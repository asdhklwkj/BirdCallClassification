{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1O6vghMicgl9",
    "outputId": "d6c4dd6c-47f8-4b8f-d8d7-8448b89cd13e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python_speech_features\n",
      "  Downloading python_speech_features-0.6.tar.gz (5.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: python_speech_features\n",
      "  Building wheel for python_speech_features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for python_speech_features: filename=python_speech_features-0.6-py3-none-any.whl size=5870 sha256=9e7580df21a64ced32e05590111d37f05e9699409a6657492758f9f71b3230bc\n",
      "  Stored in directory: /root/.cache/pip/wheels/5a/9e/68/30bad9462b3926c29e315df16b562216d12bdc215f4d240294\n",
      "Successfully built python_speech_features\n",
      "Installing collected packages: python_speech_features\n",
      "Successfully installed python_speech_features-0.6\n",
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python_speech_features\n",
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "15DWDM5vcmgB"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"모든 모듈의 난수 생성기 시드를 고정합니다.\"\"\"\n",
    "    random.seed(seed_value)  # 파이썬 내장 random 모듈\n",
    "    np.random.seed(seed_value)  # NumPy\n",
    "    torch.manual_seed(seed_value)  # CPU를 위한 PyTorch 함수\n",
    "    torch.cuda.manual_seed(seed_value)  # GPU를 위한 PyTorch 함수\n",
    "    torch.cuda.manual_seed_all(seed_value)  # 멀티 GPU를 위한 PyTorch 함수\n",
    "    torch.backends.cudnn.deterministic = True  # cudnn 알고리즘의 동작을 결정적으로 만듦\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "set_seed(42)  # 원하는 시드 값으로 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fkCnxXIzcqnP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io.wavfile import read\n",
    "from IPython.lib.display import Audio\n",
    "from scipy.fftpack import fft, ifft\n",
    "from scipy.io import loadmat\n",
    "import scipy.signal as sgnl\n",
    "import scipy.io.wavfile as wav\n",
    "import sys\n",
    "import wave\n",
    "import operator\n",
    "import scipy\n",
    "from python_speech_features import mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oON39TY5cuXO",
    "outputId": "41b57f0f-b6b0-4292-9674-17c6e63c3341"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# CUDA 사용 가능 여부 확인 및 디바이스 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9kH4UQtfcskx",
    "outputId": "ac478dce-eb07-4ca3-c9aa-6ca0e4dcaf24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/My Drive/birdcall\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# 현재 디렉토리 설정\n",
    "%cd /content/drive/My Drive/birdcall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aPLj2sJpZw73",
    "outputId": "cbe87102-42f8-4ebb-8b2b-41e1be7cf4a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: Black_legged_Kittiwake_Rissa_tridactyla, Probability: 0.8979588150978088\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.io import wavfile\n",
    "from python_speech_features import mfcc\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import wavfile, loadmat\n",
    "from scipy.fft import fft, fftfreq, ifftshift\n",
    "from scipy.fftpack import fftshift\n",
    "from python_speech_features import mfcc\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Label to index mapping dictionary as provided\n",
    "labels_index = {\n",
    "    'Velvet_Scoter_Melanitta_fusca': 0,\n",
    "    'Long_tailed_Duck_Clangula_hyemalis': 1,\n",
    "    'Leach\\'s_Storm_Petrel_Hydrobates_leucorhous': 2,\n",
    "    'Horned_Grebe_Podiceps_auritus': 3,\n",
    "    'Great_Bustard_Otis_tarda': 4,\n",
    "    'European_Turtle_Dove_Streptopelia_turtur': 5,\n",
    "    'Black_legged_Kittiwake_Rissa_tridactyla': 6,\n",
    "    'Balearic_Shearwater_Puffinus_mauretanicus': 7,\n",
    "    'Atlantic_Puffin_Fratercula_arctica': 8,\n",
    "    'Aquatic_Warbler_Acrocephalus_paludicola': 9\n",
    "}\n",
    "\n",
    "# Invert the dictionary to map indices to labels\n",
    "index_to_labels = {v: k for k, v in labels_index.items()}\n",
    "\n",
    "# 모델 클래스 정의\n",
    "class LSTMSoundClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, num_layers=3):\n",
    "        super(LSTMSoundClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size * 2)\n",
    "        self.fc2 = nn.Linear(hidden_size * 2, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "def apply_fourier_transform(input_audio, Fs):\n",
    "    N = len(input_audio)\n",
    "    f_transform = fftshift(fft(input_audio, N))\n",
    "    frequencies = np.linspace(-Fs/2, Fs/2, N)\n",
    "    return f_transform, frequencies\n",
    "\n",
    "import scipy.signal as signal\n",
    "\n",
    "\n",
    "def apply_lowpass_filter(input_audio, b, a):\n",
    "    filtered_audio = signal.lfilter(b, a, input_audio)\n",
    "    return filtered_audio\n",
    "\n",
    "def extract_mfcc_features(filtered_audio, Fs):\n",
    "    mfcc_features = mfcc(filtered_audio, Fs)\n",
    "    return mfcc_features\n",
    "\n",
    "# 사전 처리 함수 정의\n",
    "def preprocess_audio(file_path, b, a):\n",
    "    # WAV 파일 로드\n",
    "    Fs, input_audio = wavfile.read(file_path)\n",
    "\n",
    "    # 저주파 필터링 적용\n",
    "    filtered_audio = apply_lowpass_filter(input_audio, b, a)\n",
    "\n",
    "    # MFCC 추출\n",
    "    mfcc_features = mfcc(filtered_audio, samplerate=Fs, numcep=13)\n",
    "\n",
    "    return mfcc_features\n",
    "\n",
    "\n",
    "# 사용할 모델의 하이퍼파라미터 정의\n",
    "num_classes = 10  # 예시로 10개의 클래스가 있다고 가정합니다. 실제 클래스 수로 변경해주세요.\n",
    "input_size = 13  # MFCC 특성의 크기 (numcep의 값과 일치해야 함)\n",
    "hidden_size = 512\n",
    "num_layers = 3\n",
    "\n",
    "# 모델 인스턴스 생성 및 학습된 가중치 불러오기\n",
    "model = LSTMSoundClassifier(input_size=input_size, hidden_size=hidden_size, num_classes=num_classes, num_layers=num_layers)\n",
    "model.load_state_dict(torch.load('./3.23.pth'))  # 모델 경로를 'model_path.pth'에 맞게 수정하세요.\n",
    "model.eval()\n",
    "\n",
    "# 필터 계수 불러오기 - 'highpass(500).mat' 파일에 해당하는 경로를 설정하세요.\n",
    "filter_data = loadmat('./low_filter/highpass(500).mat')  # 필터 경로를 'filter_path.mat'에 맞게 수정하세요.\n",
    "Coeffs = filter_data['ba'].astype(np.float64)\n",
    "b = Coeffs[0, :]\n",
    "a = 1\n",
    "\n",
    "# 추론할 오디오 파일 경로 설정\n",
    "test_file_path = './test/Black_Legged_Kittiwake_2_TEST.wav'  # 테스트 오디오 파일 경로를 설정하세요.\n",
    "\n",
    "# 오디오 파일 사전 처리\n",
    "test_feature = preprocess_audio(test_file_path, b, a)\n",
    "test_feature_tensor = torch.tensor([test_feature], dtype=torch.float)\n",
    "\n",
    "\n",
    "# 추론 실행\n",
    "with torch.no_grad():\n",
    "    output = model(test_feature_tensor)\n",
    "    probabilities = torch.softmax(output, dim=1)\n",
    "    predicted_index = probabilities.argmax(dim=1).item()\n",
    "    predicted_prob = probabilities.max(dim=1).values.item()\n",
    "\n",
    "    # Use the index to get the associated label from our dictionary\n",
    "    predicted_label = index_to_labels[predicted_index]\n",
    "\n",
    "    print(f\"Predicted label: {predicted_label}, Probability: {predicted_prob}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
